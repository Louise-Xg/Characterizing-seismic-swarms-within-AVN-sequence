{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from AVN import *\n",
    "import scipy.io as scp\n",
    "import os\n",
    "from Restructure import *\n",
    "from new_K_seismicity_rate3 import *\n",
    "import matplotlib.patheffects as pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Define colors code for plots:\n",
    "from matplotlib import cm\n",
    "\n",
    "##Get colors : \n",
    "cmap_name1 = cm.get_cmap('tab20', 20)\n",
    "cmap_name2 = cm.get_cmap('tab20b', 20)\n",
    "cmap_name3 = cm.get_cmap('tab20c', 20)\n",
    "cmap_name4 = cm.get_cmap('tab10', 10)\n",
    "cmap_name5 = cm.get_cmap('Set3', 12)\n",
    "\n",
    "cmap1 = cmap_name1(np.linspace(0, 1, 20))\n",
    "cmap2 = cmap_name2(np.linspace(0, 1, 20))\n",
    "cmap3 = cmap_name3(np.linspace(0, 1, 20))\n",
    "cmap4 = cmap_name4(np.linspace(0, 1, 10))\n",
    "cmap5 = cmap_name5(np.linspace(0, 1, 12))\n",
    "\n",
    "cmap = np.vstack([cmap1, cmap2, cmap3, cmap4, cmap5, \n",
    "                  cmap1, cmap2, cmap3, cmap4, cmap5, \n",
    "                  cmap1, cmap2, cmap3, cmap4, cmap5,\n",
    "                  cmap1, cmap2, cmap3, cmap4, cmap5,\n",
    "                  cmap1, cmap2, cmap3, cmap4, cmap5])\n",
    "print(len(cmap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path_to_df0 = \"/home/xianglo/Bureau/DATA_AMATRICE/DBSCAN_David/new_all_run_files_for_etas_23052024_2/new_all_run_files_for_etas/catalog_all/\"\n",
    "\n",
    "####Raw data:\n",
    "df0 = pd.read_csv(path_to_df0+'raw_data_modified_version.csv')\n",
    "###Structure : t, x, y, z, m, x_km, y_km\n",
    "\n",
    "###Clusters from dbscan:\n",
    "v0_n50_d0_3 = scp.loadmat(\"dbscan_data/v0_d03km_n50_every1.mat\")[\"clusters\"].reshape(-1) ##au moins 50 séismes à < 200 m, v = 0km/d : 1 séisme sur 5 comme vertex\n",
    "\n",
    "###Add columns:\n",
    "df0[\"dbscan\"] = v0_n50_d0_3\n",
    "\n",
    "###Swarms obtained by ETAS & seismicity rate:\n",
    "df_swarms = pd.read_csv('v0_d03_n50_every1_clusters/df_final_swarms_of_v0_d03_n50_every1.csv')\n",
    "\n",
    "##Rename swarms after sorting along t1:\n",
    "df_swarms = df_swarms.sort_values(\"t1\")\n",
    "df_swarms.index = np.arange(0, len(df_swarms))\n",
    "\n",
    "df_swarms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Create a column of swarms number:\n",
    "df0[\"swarms_num\"] = np.zeros(len(df0)) -1\n",
    "\n",
    "\n",
    "for i in range(0, len(df_swarms)):\n",
    "    select_swarms = df0.index[(df0.t >= df_swarms.t1.iloc[i])&(df0.t <= df_swarms.t2.iloc[i])\n",
    "                       & (df0.x >= df_swarms.x1.iloc[i])&(df0.x <= df_swarms.x2.iloc[i])\n",
    "                       & (df0.y >= df_swarms.y1.iloc[i])&(df0.y <= df_swarms.y2.iloc[i])\n",
    "                       & (df0.z >= df_swarms.z1.iloc[i])&(df0.z <= df_swarms.z2.iloc[i])]\n",
    "    \n",
    "    df0.swarms_num.iloc[select_swarms] = i\n",
    "\n",
    "df0['swarms_num'] = df0['swarms_num'].astype(int)\n",
    "df0['dbscan'] = df0['dbscan'].astype(int)\n",
    "\n",
    "print(df0[\"swarms_num\"].max()+1)\n",
    "\n",
    "###Remove all rows with a magnitude equal to a nan value:\n",
    "df0 = df0.dropna()\n",
    "\n",
    "df0.index = np.arange(0, len(df0))\n",
    "\n",
    "df0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Define AVN MS:\n",
    "A, V, N, df_AVN = AVN(df0)\n",
    "\n",
    "df_AVN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Rescale on Norcia event:\n",
    "xN_km = df0.x_km - N.x_km\n",
    "yN_km = df0.y_km - N.y_km\n",
    "\n",
    "df0[\"xN_km\"] = xN_km\n",
    "df0[\"yN_km\"] = yN_km\n",
    "\n",
    "###Define AVN MS:\n",
    "A, V, N, df_AVN = AVN(df0)\n",
    "\n",
    "###Define EQ m >= 5: ##associated to gold color\n",
    "df0_m5 = df0[df0.m >= 5]\n",
    "\n",
    "df0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redetermine t starting swarm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time \n",
    "\n",
    "#%matplotlib inline\n",
    "\n",
    "def get_new_df_clusters(list0, Plots1 = False, Plots2 = False):\n",
    "    \n",
    "    ##Take a deeper look on swarms:\n",
    "    path = \"/home/xianglo/Bureau/DATA_AMATRICE/DBSCAN_David/new_all_run_files_for_etas_23052024_2/new_all_run_files_for_etas/v0_d03_n50_every1_clusters/output_dbscan_v0_d03_n50_every1/\"\n",
    "\n",
    "    ratio_factor = 10\n",
    "\n",
    "    all_x1 = []\n",
    "    all_x2 = []\n",
    "    all_y1 = []\n",
    "    all_y2 = []\n",
    "    all_z1 = []\n",
    "    all_z2 = []\n",
    "    all_t1 = []\n",
    "    all_t2 = []\n",
    "    all_dbscan_cluster = []\n",
    "    all_swarms_num = []\n",
    "    \n",
    "    all_new_t1 = []\n",
    "    all_dt1 = []\n",
    "    all_t = []\n",
    "    all_dn = []\n",
    "\n",
    "    for num_swarms in list0:\n",
    "        \n",
    "        print(\"###########################swarm n°\"+str(num_swarms)+\"###########################\")\n",
    "        all_swarms_num.append(num_swarms)\n",
    "\n",
    "        ###Get dbscan cluster of the studied swarm:\n",
    "        num_cluster_DBSCAN = df_swarms.num_EQ.iloc[int(num_swarms)]\n",
    "        all_dbscan_cluster.append(num_cluster_DBSCAN)\n",
    "        print(\"num_cluster_DBSCAN =\", num_cluster_DBSCAN)\n",
    "\n",
    "        ###Get dn value used for seismicity rate of dbscan cluster:\n",
    "        df2 = np_to_pd_3(path+\"dbscan_clust\"+str(num_cluster_DBSCAN)+\".dat\")\n",
    "        df00 = df2[df2.ind == 1]\n",
    "        df1 = np.cumsum(df00.ind)\n",
    "        dn = int(np.ceil(len(df00)*5/100)) ##smooth windown ##taking 5% of cluster's data\n",
    "        print(\"dn =\", dn)\n",
    "        all_dn.append(dn)\n",
    "\n",
    "        ###About DBSCAN cluster:\n",
    "        df_DBCSAN_cluster = df0[df0.dbscan == num_cluster_DBSCAN] \n",
    "\n",
    "        ###The swarm is supposed to start at index:\n",
    "        t_start = df_DBCSAN_cluster[df_DBCSAN_cluster.swarms_num == num_swarms].iloc[0]\n",
    "\n",
    "        ###If we want redetermine this t_start by taking into account dn:\n",
    "        arg0 = np.argwhere(df_DBCSAN_cluster.index == t_start.name)[0][0]\n",
    "        if arg0 <= int(dn):\n",
    "            arg = 0\n",
    "        else:\n",
    "            arg = np.argwhere(df_DBCSAN_cluster.index == t_start.name)[0][0] - int(dn)\n",
    "\n",
    "        new_t_start = df_DBCSAN_cluster.iloc[arg].t\n",
    "        print(\"new_t_start=\", round(new_t_start,2), \"before t_start=\", round(t_start.t,2), \"in d\")\n",
    "        all_new_t1.append(new_t_start)\n",
    "        all_dt1.append(np.abs(round(new_t_start,2) - round(t_start.t,2)))\n",
    "\n",
    "        ###Redefine swarm limits:\n",
    "        select_swarms = df0[df0.swarms_num == num_swarms]\n",
    "\n",
    "        new_select_swarms = df_DBCSAN_cluster[(df_DBCSAN_cluster.t >= new_t_start)&(df_DBCSAN_cluster.t <= round(select_swarms.t.max(), 2))\n",
    "                      & (df_DBCSAN_cluster.x >= select_swarms.x.min())&(df_DBCSAN_cluster.x <= select_swarms.x.max())\n",
    "                      & (df_DBCSAN_cluster.y >= select_swarms.y.min())&(df_DBCSAN_cluster.y <= select_swarms.y.max())\n",
    "                      & (df_DBCSAN_cluster.z >= select_swarms.z.min())&(df_DBCSAN_cluster.z <= select_swarms.z.max())]\n",
    "        \n",
    "        centro = np.array([np.mean(new_select_swarms.t.values),\n",
    "                       np.mean(new_select_swarms.y_km.values),\n",
    "                       np.mean(new_select_swarms.x_km.values), \n",
    "                       np.mean(new_select_swarms.z.values)])\n",
    "\n",
    "        all_x1.append(round(new_select_swarms.x.min(),3))\n",
    "        all_x2.append(round(new_select_swarms.x.max(),3))\n",
    "        all_y1.append(round(new_select_swarms.y.min(),3))\n",
    "        all_y2.append(round(new_select_swarms.y.max(),3))\n",
    "        all_z1.append(round(new_select_swarms.z.min(),3))\n",
    "        all_z2.append(round(new_select_swarms.z.max(),3))\n",
    "        all_t1.append(t_start.t) ##new t_start --> Modification, we put here the original t_start\n",
    "        all_t2.append(new_select_swarms.t.max()) ##doesn't change, the end of the swarm is still the same\n",
    "\n",
    "        ###Duration of swarm:\n",
    "        duration = new_select_swarms.t.max() - new_select_swarms.t.min() ##end of teh swarm - new t_start\n",
    "        print(\"(new) swarm duration =\", np.ceil(duration), \"d\")\n",
    "\n",
    "        ###Parameter:\n",
    "        t = np.ceil(duration)*1.25 ##d\n",
    "        print(\"parameter t =\", t, \"d\")\n",
    "        all_t.append(t)\n",
    "\n",
    "        ###Compute seismicity rate:                    \n",
    "        ###Observed data: \n",
    "        dff = df1\n",
    "        EQ1_rate = seismicity_rate2 (dn, df00, dff)\n",
    "\n",
    "        ###The model data:\n",
    "        dff = df00.lam\n",
    "        EQ2_rate = seismicity_rate2 (dn, df00, dff)\n",
    "\n",
    "        ###obs/mod:\n",
    "        ratio = EQ1_rate/EQ2_rate\n",
    "\n",
    "        ###About ylim:\n",
    "        ind = df1[(df00.t >= new_select_swarms.t.min())&(df00.t <= new_select_swarms.t.max())]\n",
    "        ind2 = df00.lam[(df00.t >= new_select_swarms.t.min())&(df00.t <= new_select_swarms.t.max())]\n",
    "        print(\"Observed data: Nb of EQ recorded =\", round(ind.max() - ind.min() +1,2)) ##zéro compris!\n",
    "        print(\"Model data: Nb of EQ predicted =\", round(ind2.max()- ind2.min() +1,2)) ##zéro compris!    \n",
    "\n",
    "        ###Plots:\n",
    "        if Plots1:\n",
    "            plt.figure(figsize=(18,5))\n",
    "            plt.plot(df00.t,ratio)\n",
    "            plt.xlabel(\"Time (d)\")\n",
    "            plt.ylabel(\"Ratio (obs/mod)\")\n",
    "            plt.axhline(y=ratio_factor, linewidth=2, color=cmap[int(num_swarms)], ls = '--')\n",
    "            plt.axvline(x=new_select_swarms.t.min(), linewidth=2, color=cmap[int(num_swarms)], ls = '--')\n",
    "            plt.axvline(x=t_start.t, linewidth=2, color='gray', ls = '--')\n",
    "            plt.axvline(x=new_select_swarms.t.max(), linewidth=2, color=cmap[int(num_swarms)], ls = '--')\n",
    "            plt.grid(True)\n",
    "            plt.show()\n",
    "\n",
    "            plt.figure(figsize=(18,10))\n",
    "            plt.subplot(2,1,1)\n",
    "            plt.plot(df00.t, df1, '-k', label=\"observed data\")\n",
    "            plt.plot(df00.t, df00.lam, c='crimson', label=\"model\")\n",
    "            plt.axvline(x=new_select_swarms.t.min(), linewidth=2, color=cmap[int(num_swarms)], ls = '--')\n",
    "            plt.axvline(x=t_start.t, linewidth=2, color='gray', ls = '--')\n",
    "            plt.axvline(x=new_select_swarms.t.max(), linewidth=2, color=cmap[int(num_swarms)], ls = '--')\n",
    "            plt.xlabel(\"Time (d)\")\n",
    "            plt.ylabel(\"Cumulative seismic events\")\n",
    "            plt.xlim(new_select_swarms.t.min()-t, new_select_swarms.t.max()+t)\n",
    "            plt.ylim(np.min([ind.iloc[0], ind2.iloc[0]])-100, df2.lam.max())\n",
    "            plt.grid(True)\n",
    "            plt.legend()\n",
    "\n",
    "            plt.subplot(2,1,2)\n",
    "            plt.plot(df00.t, EQ1_rate, '-k', label = \"observed data\")\n",
    "            plt.plot(df00.t, EQ2_rate, c = \"crimson\", label = \"model\")\n",
    "            plt.xlabel(\"Time (d)\")\n",
    "            plt.ylabel(\"Seismicity rate\")\n",
    "            plt.yscale(\"log\")\n",
    "            plt.axvline(x=new_select_swarms.t.min(), linewidth=2, color=cmap[int(num_swarms)], ls = '--')\n",
    "            plt.axvline(x=t_start.t, linewidth=2, color='gray', ls = '--')\n",
    "            plt.axvline(x=new_select_swarms.t.max(), linewidth=2, color=cmap[int(num_swarms)], ls = '--')\n",
    "            plt.xlim(new_select_swarms.t.min()-t, new_select_swarms.t.max()+t)\n",
    "            plt.ylim(0, np.max([EQ1_rate, EQ2_rate]))\n",
    "            plt.grid(True)\n",
    "            plt.legend()\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "        ###At -t <=> t days before the occurence of the swarm:\n",
    "        swarms_bf = df0[(df0.t >= round(new_select_swarms.t.min()-t, 2))&(df0.t <= new_select_swarms.t.min())\n",
    "                      & (df0.x >= new_select_swarms.x.min())&(df0.x <= new_select_swarms.x.max())\n",
    "                      & (df0.y >= new_select_swarms.y.min())&(df0.y <= new_select_swarms.y.max())\n",
    "                      & (df0.z >= new_select_swarms.z.min())&(df0.z <= new_select_swarms.z.max())]\n",
    "        #At +t <=> t days after the occurence of the swarm:\n",
    "        swarms_af = df0[(df0.t >= new_select_swarms.t.max())&(df0.t <= round(new_select_swarms.t.max()+t, 2))\n",
    "                      & (df0.x >= new_select_swarms.x.min())&(df0.x <= new_select_swarms.x.max())\n",
    "                      & (df0.y >= new_select_swarms.y.min())&(df0.y <= new_select_swarms.y.max())\n",
    "                      & (df0.z >= new_select_swarms.z.min())&(df0.z <= new_select_swarms.z.max())]\n",
    "\n",
    "        ##Cluster along the time [swarm0.t - t; swarm0.t + t]:\n",
    "        swarms_t = df0[(df0.t >= round(new_select_swarms.t.min()-t, 2))&(df0.t <= round(new_select_swarms.t.max()+t, 2))\n",
    "                      & (df0.x >= new_select_swarms.x.min())&(df0.x <= new_select_swarms.x.max())\n",
    "                      & (df0.y >= new_select_swarms.y.min())&(df0.y <= new_select_swarms.y.max())\n",
    "                      & (df0.z >= new_select_swarms.z.min())&(df0.z <= new_select_swarms.z.max())]\n",
    "\n",
    "        ###About EQ m >= 3.5:\n",
    "        EQ_m = df0[(df0.t >= round(new_select_swarms.t.min()-t, 2))&(df0.t <= round(new_select_swarms.t.max()+t, 2))\n",
    "                      & (df0.m >= 3.5)]\n",
    "        EQ_m = EQ_m.sort_values([\"t\"], ascending=True)\n",
    "\n",
    "        ##Distance between those EQ and the centroid of the swarm:\n",
    "        if EQ_m.empty == False:\n",
    "            distances = np.sqrt((EQ_m.y_km.values - centro[1])**2 + (EQ_m.x_km.values - centro[2])**2 + (EQ_m.z.values - centro[3])**2) ##euclidean distance in km\n",
    "\n",
    "\n",
    "        if Plots2:\n",
    "            ###Plot lat, lon, mag vs t:\n",
    "            plt.figure(figsize=(18,15))\n",
    "            plt.subplot(3,1,1)\n",
    "            plt.scatter(swarms_t.t, swarms_t.yN_km, s=np.exp(4*swarms_t.m), facecolors='none', edgecolors='k', linewidths=1, label='swarm n°'+str(int(num_swarms)))\n",
    "            #plt.plot(centro[0], centro[1], \"*\", c='gold', markersize=10)\n",
    "            if EQ_m.empty == False:\n",
    "                plt.scatter(EQ_m.t, EQ_m.yN_km, s=np.exp(2*EQ_m.m), facecolors='none', edgecolors='salmon', linewidths=1)\n",
    "                for j in range(0, len(distances)):\n",
    "                    plt.annotate(str(abs(int(distances[j]))), (EQ_m.t.iloc[j], EQ_m.y_km.iloc[j]),\n",
    "                                 color='r', alpha =1, size=13, \n",
    "                                #bbox=dict(boxstyle='round,pad=0.2', fc='yellow', alpha=0.5), \n",
    "                                path_effects=[pe.withStroke(linewidth=1, foreground=\"k\")])\n",
    "    #         plt.scatter(EQ_xy.t, EQ_xy.yN_km, s=6*np.exp(EQ_xy.m), facecolors='none', edgecolors='salmon', linewidths=1)\n",
    "            if not swarms_t[(swarms_t.t == A.t)].empty == True :\n",
    "                plt.scatter(A.t, A.yN_km, s=np.exp(A.m), marker='*', edgecolors='tab:red', linewidths=1)\n",
    "            if not swarms_t[(swarms_t.t == V.t)].empty == True :\n",
    "                plt.scatter(V.t, V.yN_km, s=np.exp(V.m), marker='*', edgecolors='tab:red', linewidths=1)\n",
    "            if not swarms_t[(swarms_t.t == N.t)].empty == True :\n",
    "                plt.scatter(N.t, N.yN_km, s=np.exp(N.m), marker='*', edgecolors='tab:red', linewidths=1)\n",
    "            plt.axvline(x=new_select_swarms.t.min(), linewidth=2, color=cmap[int(num_swarms)], ls = '--')\n",
    "            plt.axvline(x=t_start.t, linewidth=2, color='gray', ls = '--')\n",
    "            plt.axvline(x=new_select_swarms.t.max(), linewidth=2, color=cmap[int(num_swarms)], ls = '--')\n",
    "            plt.axhline(y=df_DBCSAN_cluster.yN_km.min(), linewidth=2, color='lavender', ls = '--')\n",
    "            plt.axhline(y=df_DBCSAN_cluster.yN_km.max(), linewidth=2, color='lavender', ls = '--')\n",
    "            plt.xlim(new_select_swarms.t.iloc[0]-t, new_select_swarms.t.iloc[-1]+t)\n",
    "            plt.ylim(swarms_t.yN_km.min()-5, swarms_t.yN_km.max()+5)\n",
    "            plt.xlabel(\"Time (d)\")\n",
    "            plt.ylabel(\"Longitude (km)\")\n",
    "            plt.grid(True)\n",
    "\n",
    "            plt.subplot(3,1,2)\n",
    "            plt.scatter(swarms_t.t, swarms_t.xN_km, s=np.exp(4*swarms_t.m), facecolors='none', edgecolors='k', linewidths=1, label='swarm n°'+str(int(num_swarms)))\n",
    "            #plt.plot(centro[0], centro[2], \"*\", c='gold', markersize=10)\n",
    "            if EQ_m.empty == False:\n",
    "                plt.scatter(EQ_m.t, EQ_m.xN_km, s=np.exp(2*EQ_m.m), facecolors='none', edgecolors='salmon', linewidths=1)\n",
    "                for j in range(0, len(distances)):\n",
    "                    plt.annotate(str(abs(int(distances[j]))), (EQ_m.t.iloc[j], EQ_m.x_km.iloc[j]),\n",
    "                                 color='r', alpha =1, size=13, \n",
    "                                #bbox=dict(boxstyle='round,pad=0.2', fc='yellow', alpha=0.5), \n",
    "                                path_effects=[pe.withStroke(linewidth=1, foreground=\"k\")])\n",
    "\n",
    "    #         plt.scatter(EQ_xy.t, EQ_xy.xN_km, s=6*np.exp(EQ_xy.m), facecolors='none', edgecolors='salmon', linewidths=1)\n",
    "            if not swarms_t[(swarms_t.t == A.t)].empty == True :\n",
    "                plt.scatter(A.t, A.xN_km, s=np.exp(A.m), marker='*', edgecolors='tab:red', linewidths=1)\n",
    "            if not swarms_t[(swarms_t.t == V.t)].empty == True :\n",
    "                plt.scatter(V.t, V.xN_km, s=np.exp(V.m), marker='*', edgecolors='tab:red', linewidths=1)\n",
    "            if not swarms_t[(swarms_t.t == N.t)].empty == True :\n",
    "                plt.scatter(N.t, N.xN_km, s=np.exp(N.m), marker='*', edgecolors='tab:red', linewidths=1)\n",
    "            plt.axvline(x=new_select_swarms.t.min(), linewidth=2, color=cmap[int(num_swarms)], ls = '--')\n",
    "            plt.axvline(x=t_start.t, linewidth=2, color='gray', ls = '--')\n",
    "            plt.axvline(x=new_select_swarms.t.max(), linewidth=2, color=cmap[int(num_swarms)], ls = '--')\n",
    "            plt.axhline(y=df_DBCSAN_cluster.xN_km.min(), linewidth=2, color='lavender', ls = '--')\n",
    "            plt.axhline(y=df_DBCSAN_cluster.xN_km.max(), linewidth=2, color='lavender', ls = '--')\n",
    "            plt.xlim(new_select_swarms.t.iloc[0]-t, new_select_swarms.t.iloc[-1]+t)\n",
    "            plt.ylim(swarms_t.xN_km.min()-5, swarms_t.xN_km.max()+5)\n",
    "            plt.xlabel(\"Time (d)\")\n",
    "            plt.ylabel(\"Latitude(km)\")\n",
    "            plt.grid(True)\n",
    "\n",
    "            plt.subplot(3,1,3)\n",
    "            plt.scatter(swarms_t.t, swarms_t.m, s=np.exp(4*swarms_t.m), facecolors='none', edgecolors='k', linewidths=1, label='swarm n°'+str(int(num_swarms)))\n",
    "            if EQ_m.empty == False:\n",
    "                plt.scatter(EQ_m.t, EQ_m.m, s=np.exp(2*EQ_m.m), facecolors='none', edgecolors='salmon', linewidths=1)\n",
    "                for j in range(0, len(distances)):\n",
    "                    plt.annotate(str(abs(int(distances[j]))), (EQ_m.t.iloc[j], EQ_m.m.iloc[j]),\n",
    "                                 color='r', alpha =1, size=13, \n",
    "                                #bbox=dict(boxstyle='round,pad=0.2', fc='yellow', alpha=0.5), \n",
    "                                path_effects=[pe.withStroke(linewidth=1, foreground=\"k\")])\n",
    "\n",
    "    #         plt.scatter(EQ_xy.t, EQ_xy.m, s=np.exp(2*EQ_xy.m), facecolors='none', edgecolors='salmon', linewidths=1)\n",
    "            if not swarms_t[(swarms_t.t == A.t)].empty == True :\n",
    "                plt.scatter(A.t, A.m, s=np.exp(A.m), marker='*', edgecolors='tab:red', linewidths=1)\n",
    "            if not swarms_t[(swarms_t.t == V.t)].empty == True :\n",
    "                plt.scatter(V.t, V.m, s=np.exp(V.m), marker='*', edgecolors='tab:red', linewidths=1)\n",
    "            if not swarms_t[(swarms_t.t == N.t)].empty == True :\n",
    "                plt.scatter(N.t, N.m, s=np.exp(N.m), marker='*', edgecolors='tab:red', linewidths=1)\n",
    "            plt.axvline(x=new_select_swarms.t.min(), linewidth=2, color=cmap[int(num_swarms)], ls = '--')\n",
    "            plt.axvline(x=t_start.t, linewidth=2, color='gray', ls = '--')\n",
    "            plt.axvline(x=new_select_swarms.t.max(), linewidth=2, color=cmap[int(num_swarms)], ls = '--')\n",
    "            plt.axhline(y=df_DBCSAN_cluster.m.min(), linewidth=2, color='lavender', ls = '--')\n",
    "            plt.axhline(y=df_DBCSAN_cluster.m.max(), linewidth=2, color='lavender', ls = '--')\n",
    "            plt.xlim(new_select_swarms.t.iloc[0]-t, new_select_swarms.t.iloc[-1]+t)\n",
    "            plt.xlabel(\"Time (d)\")\n",
    "            plt.ylabel(\"Magnitude \")\n",
    "            plt.grid(True)\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "            ###Plots map along the time t:\n",
    "            plt.figure(figsize=(18,10))\n",
    "            plt.subplot(1,3,1)\n",
    "            plt.scatter(swarms_bf.yN_km, swarms_bf.xN_km, s=np.exp(4*swarms_bf.m), facecolors='none', edgecolors='k', linewidths=0.5, label='EQ')\n",
    "            plt.xlabel(\"Longitude (km)\")\n",
    "            plt.ylabel(\"Latitude (km)\")\n",
    "            plt.title(\"Localization of swarm n°\"+str(int(num_swarms))+\", \\n for t = [\"+str(round(swarms_bf.t.iloc[0],1))+\";\"+str(round(swarms_bf.t.iloc[-1],1))+\"] d\")\n",
    "            plt.xlim(new_select_swarms.yN_km.min(), new_select_swarms.yN_km.max())\n",
    "            plt.ylim(new_select_swarms.xN_km.min(), new_select_swarms.xN_km.max())\n",
    "            plt.gca().set_aspect('equal', adjustable='box')\n",
    "            plt.grid(True)\n",
    "\n",
    "            plt.subplot(1,3,2)\n",
    "            plt.scatter(select_swarms.yN_km, select_swarms.xN_km, s=np.exp(4*select_swarms.m), facecolors='none', edgecolors='k', linewidths=0.5, label='EQ')\n",
    "            plt.xlabel(\"Longitude (km)\")\n",
    "            plt.ylabel(\"Latitude (km)\")\n",
    "            plt.title(\"Localization of swarm n°\"+str(int(num_swarms))+\", \\n for t = [\"+str(round(select_swarms.t.iloc[0],1))+\";\"+str(round(select_swarms.t.iloc[-1],1))+\"] d\")\n",
    "            plt.xlim(new_select_swarms.yN_km.min(), new_select_swarms.yN_km.max())\n",
    "            plt.ylim(new_select_swarms.xN_km.min(), new_select_swarms.xN_km.max())\n",
    "            plt.gca().set_aspect('equal', adjustable='box')\n",
    "            plt.grid(True)\n",
    "\n",
    "            plt.subplot(1,3,3)\n",
    "            plt.scatter(swarms_af.yN_km, swarms_af.xN_km, s=np.exp(4*swarms_af.m), facecolors='none', edgecolors='k', linewidths=0.5, label='EQ')\n",
    "            plt.xlabel(\"Longitude (km)\")\n",
    "            plt.ylabel(\"Latitude (km)\")\n",
    "            plt.title(\"Localization of swarm n°\"+str(int(num_swarms))+\", \\n for t = [\"+str(round(swarms_af.t.iloc[0],1))+\";\"+str(round(swarms_af.t.iloc[-1],1))+\"] d\")\n",
    "            plt.xlim(new_select_swarms.yN_km.min(), new_select_swarms.yN_km.max())\n",
    "            plt.ylim(new_select_swarms.xN_km.min(), new_select_swarms.xN_km.max())\n",
    "            plt.gca().set_aspect('equal', adjustable='box')\n",
    "            plt.grid(True)\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "    # ###Create a new df:\n",
    "    all_x1 = np.array(all_x1)\n",
    "    all_x2 = np.array(all_x2)\n",
    "    all_y1 = np.array(all_y1)\n",
    "    all_y2 = np.array(all_y2)\n",
    "    all_z1 = np.array(all_z1)\n",
    "    all_z2 = np.array(all_z2)\n",
    "    all_t1 = np.array(all_t1)\n",
    "    all_t2 = np.array(all_t2)\n",
    "    all_dbscan_cluster = np.array(all_dbscan_cluster)\n",
    "    all_swarms_num = np.array(all_swarms_num)\n",
    "    \n",
    "    all_new_t1 = np.array(all_new_t1)\n",
    "    all_dt1 = np.array(all_dt1)\n",
    "    all_t = np.array(all_t)\n",
    "    all_dn = np.array(all_dn)\n",
    "\n",
    "    data = {\"t1\": all_t1, \"t2\":all_t2, \"x1\":all_x1, \"x2\":all_x2, \"y1\":all_y1, \"y2\":all_y2,\n",
    "            \"z1\":all_z1, \"z2\":all_z2, \"num_EQ\":all_dbscan_cluster, \"swarms_num\":all_swarms_num, \n",
    "            \"new_t1\": all_new_t1, \"dt1\": all_dt1, \"t\": all_t, \"dn\": all_dn}\n",
    "    new_df_list0 = pd.DataFrame(data)\n",
    "    \n",
    "    return new_df_list0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "list0 = np.arange(0, len(df_swarms))\n",
    "new_df_list0 = get_new_df_clusters (list0, Plots1 = False, Plots2 = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get new values for stats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delay_time_statistics(new_df) :\n",
    "\n",
    "    ###Time difference in days:\n",
    "\n",
    "    all_dbscan_cluster = []\n",
    "    all_param1 = [] ##number of the biggest EQ/ len(swarms) <=> index I\n",
    "    all_big_t = []  ##no used at the end...\n",
    "    all_diff_m_start = [] ##o used at the end...\n",
    "    all_diff_m_from4 = [] ##used\n",
    "    all_i_stars = [] ##used\n",
    "    all_skew = []  ##no used at the end...\n",
    "\n",
    "    for num_swarm in new_df.swarms_num.values :\n",
    "        \n",
    "        select_ind_swarm = new_df[new_df.swarms_num == num_swarm].index[0]\n",
    "\n",
    "        df_clust = 0\n",
    "\n",
    "        ##Select data:\n",
    "        df_clust = df0[(df0.t >= new_df.new_t1.iloc[select_ind_swarm])&(df0.t <= new_df.t2.iloc[select_ind_swarm])\n",
    "                       & (df0.x >= new_df.x1.iloc[select_ind_swarm])&(df0.x <= new_df.x2.iloc[select_ind_swarm])\n",
    "                       & (df0.y >= new_df.y1.iloc[select_ind_swarm])&(df0.y <= new_df.y2.iloc[select_ind_swarm])\n",
    "                       & (df0.z >= new_df.z1.iloc[select_ind_swarm])&(df0.z <= new_df.z2.iloc[select_ind_swarm])]\n",
    "        df_clust.index=np.arange(len(df_clust))\n",
    "        \n",
    "        ##Save dbscan cluster origin:\n",
    "        all_dbscan_cluster.append(new_df.num_EQ.iloc[select_ind_swarm]) \n",
    "\n",
    "        ##Compute new t:\n",
    "        df_clust[\"new_t\"] = df_clust.t - df_clust.t.iloc[0] ##based on new_t1 and df0 !\n",
    "        \n",
    "        ##Sort magnitude:\n",
    "        df_clust = df_clust.sort_values(\"m\", ascending = False)\n",
    "        \n",
    "        ##Ratio:\n",
    "        ratio = df_clust[df_clust.m.values == df_clust.m.max()].index/len(df_clust)\n",
    "        all_param1.append(ratio)\n",
    "\n",
    "        ##For swarms, the delay between biggest event and the first event shouldn't be close...\n",
    "\n",
    "        #######SHEARER 2016:\n",
    "        ##Compute mean(or median) of new_t:\n",
    "        tbar = df_clust.new_t.mean()\n",
    "#         tbar = df_clust.new_t.median()\n",
    "\n",
    "        ##Attribut T:\n",
    "        ##Find t of biggest EQ:\n",
    "        tm = df_clust.new_t[df_clust.m == df_clust.m.max()].values\n",
    "        big_t = tm/tbar\n",
    "        all_big_t.append(big_t)\n",
    "\n",
    "        ##Attribut diff in time between the biggest EQ and other EQ:\n",
    "        diff_m = df_clust.m[df_clust.m == df_clust.m.max()].values - df_clust.m.values \n",
    "        df_clust[\"diff_m\"] = diff_m\n",
    "        \n",
    "        ##Attribut diff in magnitude between the 1st biggest EQ and the biggest EQ:\n",
    "        all_diff_m_start.append(df_clust.diff_m.iloc[1])\n",
    "        ##Attribut diff in magnitude between the 4th biggest EQ  and the biggest EQ:\n",
    "        all_diff_m_from4.append(df_clust.diff_m.iloc[3])\n",
    "            \n",
    "        ##Attribut t*:\n",
    "        M = 10**(1.5*df_clust.m.values + 9.1)\n",
    "        i_stars = np.sum(M*df_clust.index+1)/np.sum(M)\n",
    "        i_stars = i_stars/len(df_clust) #normalized\n",
    "        all_i_stars.append(i_stars)\n",
    "\n",
    "        #######SHEARER 2011:\n",
    "        ##Compute moment release Mo(i):\n",
    "        Mo = 10**(1.5*df_clust.m.values+9.1) \n",
    "\n",
    "        ##Compute weight mean time tbar:\n",
    "        tbar = np.sum(df_clust.new_t.values * Mo)/(np.sum(Mo))\n",
    "\n",
    "        ##Compute individulal moment normalized mo:\n",
    "        mo = Mo/np.sum(Mo)\n",
    "\n",
    "        ##Compute the third central moment mu3:\n",
    "        mu3 = np.sum((df_clust.new_t - tbar)**3 * mo)\n",
    "\n",
    "        ##Compute standard deviation sigma:\n",
    "        sigma = (np.sum((df_clust.new_t - tbar)**2 * mo))**(1/2)\n",
    "\n",
    "        ##Skewness of moment release skew:\n",
    "        skew = mu3/sigma\n",
    "        all_skew.append(skew)\n",
    "        \n",
    "    all_dbscan_cluster = np.array(all_dbscan_cluster)\n",
    "    all_param1 = np.array(all_param1)\n",
    "    all_big_t = np.array(all_big_t)\n",
    "    all_diff_m_start = np.array(all_diff_m_start)\n",
    "    all_diff_m_from4 = np.array(all_diff_m_from4)\n",
    "    all_i_stars = np.array(all_i_stars)\n",
    "    all_skew = np.array(all_skew)\n",
    "    \n",
    "    data = {\"dbscan_cluster\":all_dbscan_cluster,\n",
    "            \"param1\":all_param1.reshape(-1),\n",
    "            \"T\":all_big_t.reshape(-1),\n",
    "            \"i_stars\":all_i_stars,\n",
    "            \"diff_m\":all_diff_m_from4, \n",
    "            \"skew\":all_skew}\n",
    "#     print(len(all_dbscan_cluster), len(all_param1), len(all_big_t), len(all_diff_m_from4), len(all_t_stars), len(all_skew))\n",
    "#     print(all_dbscan_cluster, all_param1, all_big_t, all_diff_m_from4, all_t_stars, all_skew)\n",
    "    df_final = pd.DataFrame(data)\n",
    "    \n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_stats0 = delay_time_statistics(new_df_list0)\n",
    "df_stats0[\"swarm_number\"] = list0\n",
    "\n",
    "df_stats0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##Concatenate previous table with general characteristics and the table of statistics data:\n",
    "#new_df_listx: statistics data, df_statsx:general characteristics\n",
    "df_stats0_ = pd.concat([new_df_list0, df_stats0], ignore_index=True, axis=1, join=\"inner\")\n",
    "rename_stats0 = np.concatenate([list(new_df_list0.columns), list(df_stats0.columns)])\n",
    "#df_stats0_.set_axis(rename_stats0, axis=1,inplace=True)\n",
    "df_stats0_ = df_stats0_.set_axis(axis=1, labels=rename_stats0)\n",
    "df_stats0_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##Concatenate all df_statsx:\n",
    "df_stats = df_stats0_\n",
    "df_stats = df_stats.sort_values(\"swarm_number\")\n",
    "df_stats.index = np.arange(0, len(df_stats))\n",
    "df_stats[\"swarm_number\"] = np.arange(1, len(df_stats)+1)\n",
    "\n",
    "path = \"/home/xianglo/Bureau/DATA_AMATRICE/DBSCAN_David/new_all_run_files_for_etas_23052024_2/new_all_run_files_for_etas/v0_d03_n50_every1_clusters/Saving_t_start_df/\"\n",
    "if not os.path.exists(path):\n",
    "    os.mkdir(path)\n",
    "\n",
    "#df_stats.to_csv(path+\"df_stats.csv\", index=False)\n",
    "\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "###Saving dataframe:\n",
    "##Create directory for saving refine t_start datframes:\n",
    "savedir = \"/home/xianglo/Bureau/DATA_AMATRICE/DBSCAN_David/new_all_run_files_for_etas_23052024_2/new_all_run_files_for_etas/v0_d03_n50_every1_clusters/Saving_t_start_df/\"\n",
    "if not os.path.exists(savedir):\n",
    "    os.mkdir(savedir)\n",
    "    \n",
    "#df_stats0_.to_csv(savedir+\"df_stats0_redefine_tstart.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the final swarms df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###Concantenate all kind swarms list into a df:\n",
    "new_df = new_df_list0\n",
    "###Sort them:\n",
    "new_df = new_df.sort_values(by=['swarms_num'], ascending=True, ignore_index=True)\n",
    "###Rename swarm:\n",
    "new_df[\"swarms_num\"]  = np.arange(1, len(new_df)+1)\n",
    "\n",
    "###Remove the 1 swarms af:\n",
    "#new_df = new_df.drop(index=([12+1, 14+1])) ##12 and 14 are after rename step beginning with 0...\n",
    "new_df = new_df.drop(index=([12+1])) ##only A after meeting 12122023\n",
    "\n",
    "###Redefine df index after removing af, we keep every other swarms:\n",
    "new_df.index = np.arange(0, len(new_df))\n",
    "\n",
    "new_df##nt1 is the redefined t_start of the swarms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Based on the initial dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_df = df_swarms.copy()\n",
    "###Remove the 1 swarm af:\n",
    "#new_df = new_df.drop(index=([12+1, 14+1]))\n",
    "new_df = new_df.drop(index=([12+1])) ##only A after meeting 12122023\n",
    "###Redefine df index after removing af, we keep every other swarms:\n",
    "new_df.index = np.arange(0, len(new_df))\n",
    "\n",
    "new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After getting migration behaviour data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##Concatenate all df_statsx:\n",
    "df_stats = pd.concat([df_stats0_], ignore_index=True)\n",
    "df_stats.sort_values(\"swarm_number\", inplace=True)\n",
    "df_stats.index = np.arange(0, len(df_stats))\n",
    "df_stats[\"swarms_num\"]  = np.arange(1, len(df_stats)+1)\n",
    "\n",
    "##Rename AF and swarms:\n",
    "renum = np.concatenate((np.arange(1, 13), [-99], np.arange(13,41))) ##only A after meeting 12122023\n",
    "df_stats[\"swarm_number\"] = renum\n",
    "\n",
    "df_stats.to_csv(\"/home/xianglo/Bureau/DATA_AMATRICE/DBSCAN_David/new_all_run_files_for_etas_23052024_2/new_all_run_files_for_etas/v0_d03_n50_every1_clusters/Saving_t_start_df/df_stats.csv\", index=False)\n",
    "\n",
    "df_stats.drop([\"dt1\",\"t\",\"dn\",\"param1\",\"T\",\"i_stars\",\"diff_m\",\"skew\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##Add migration swarms:\n",
    "dfM = pd.read_csv(\"/home/xianglo/Bureau/DATA_AMATRICE/DBSCAN_David/new_all_run_files_for_etas_23052024_2/new_all_run_files_for_etas/v0_d03_n50_every1_clusters/dfM.csv\")\n",
    "\n",
    "##And without:\n",
    "dfNM = pd.read_csv(\"/home/xianglo/Bureau/DATA_AMATRICE/DBSCAN_David/new_all_run_files_for_etas_23052024_2/new_all_run_files_for_etas/v0_d03_n50_every1_clusters/dfNM.csv\")\n",
    "\n",
    "dfM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####For paper:\n",
    "marker_size = 300\n",
    "marker_size_l = 500\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "\n",
    "##Swarms with migration:\n",
    "for j in dfM.I.values:\n",
    "    if j == dfM.I.values[0]:\n",
    "        plt.scatter(df_stats[df_stats.swarm_number == j].param1, df_stats[df_stats.swarm_number == j].diff_m, marker='s', c='k', s=marker_size, linewidth=2, label=\"swarm-type with migration\")\n",
    "    else:\n",
    "        plt.scatter(df_stats[df_stats.swarm_number == j].param1, df_stats[df_stats.swarm_number == j].diff_m, marker='s', c='k', s=marker_size, linewidth=2)\n",
    "    \n",
    "    if j==10:\n",
    "        plt.annotate(str(j), \n",
    "              (df_stats[df_stats.swarm_number == j].param1, df_stats[df_stats.swarm_number == j].diff_m),\n",
    "               color=cmap[int(df_stats.swarm_number.iloc[j])], alpha =1, size=20, \n",
    "               path_effects=[pe.withStroke(linewidth=3, foreground=\"k\")])\n",
    "\n",
    "##Swarms without migration:\n",
    "for j in dfNM.I.values:\n",
    "    if j == dfNM.I.values[0]:\n",
    "        plt.scatter(df_stats[df_stats.swarm_number == j].param1, df_stats[df_stats.swarm_number == j].diff_m, marker='s', s=marker_size, linewidth=2, facecolors='none', edgecolors='k', label='swarm-type without migration')\n",
    "    else:\n",
    "        plt.scatter(df_stats[df_stats.swarm_number == j].param1, df_stats[df_stats.swarm_number == j].diff_m, marker='s', s=marker_size, linewidth=2, facecolors='none', edgecolors='k')\n",
    "#     plt.annotate(str(j), \n",
    "#                 (df_stats[df_stats.swarm_number == j].param1, df_stats[df_stats.swarm_number == j].diff_m),\n",
    "#                 color=cmap[int(df_stats.swarm_number.iloc[j])], alpha =1, size=15, \n",
    "#                 path_effects=[pe.withStroke(linewidth=1, foreground=\"k\")])\n",
    "        \n",
    "##Adding AF:\n",
    "letters = [\"A\"]\n",
    "for i in [12+1]:\n",
    "    if i == 12+1:\n",
    "        L = letters[0]\n",
    "        plt.scatter(df_stats[df_stats.swarms_num == i].param1, df_stats[df_stats.swarms_num == i].diff_m, marker='^', s=marker_size_l, linewidth=1, facecolors='c', edgecolors='k', label=\"aftershock-type\")\n",
    "    \n",
    "    plt.annotate(str(L), \n",
    "                 (df_stats[df_stats.swarms_num == i].param1, df_stats[df_stats.swarms_num == i].diff_m),\n",
    "                 color='r', alpha =1, size=20, \n",
    "                 path_effects=[pe.withStroke(linewidth=3, foreground=\"k\")])\n",
    "\n",
    "    \n",
    "plt.ylabel(\"Magnitude difference  $\\delta m$\", fontsize=20)\n",
    "plt.xlabel(\"Normalized index $I$\", fontsize=20)\n",
    "plt.tick_params(axis='both',labelsize=15)\n",
    "plt.legend(fontsize=14)\n",
    "#plt.axis('scaled')\n",
    "plt.xlim([0,1])\n",
    "plt.yticks(np.arange(0,3,0.2))\n",
    "plt.grid(True)\n",
    "plt.savefig(path+\"Validation_step_dmvsI.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
